# LLASA-Trainer

[æ—¥æœ¬èª](#æ—¥æœ¬èª) | [English](#english)

---

## æ—¥æœ¬èª

### æ¦‚è¦

LLASA-Trainerã¯ã€LLASA-3Bï¼ˆLarge Language Audio Speech Architectureï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’LoRAã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹é«˜å“è³ªãªæ—¥æœ¬èªTTSã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã‚’æ”¯æ´ã—ã¾ã™ã€‚

### ç‰¹å¾´

- ğŸ¯ **LoRAãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: åŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªä½¿ç”¨ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
- ğŸµ **XCodec2çµ±åˆ**: é«˜å“è³ªãªéŸ³å£°ç”Ÿæˆã®ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯
- ğŸ¤ **Gradio Web UI**: ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®éŸ³å£°ç”Ÿæˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- ğŸ“Š **å­¦ç¿’ä¸­ãƒ†ã‚¹ãƒˆ**: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«éŸ³å£°å“è³ªã‚’è‡ªå‹•ç¢ºèª
- âš™ï¸ **æŸ”è»Ÿãªè¨­å®š**: YAMLãƒ™ãƒ¼ã‚¹ã®è¨­å®šç®¡ç†
- ğŸš€ **ç°¡å˜ãªãƒ‡ãƒ—ãƒ­ã‚¤**: ã‚·ãƒ³ãƒ—ãƒ«ãªã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

### å¿…è¦è¦ä»¶

- Python 3.8+
- CUDAå¯¾å¿œGPUï¼ˆæ¨å¥¨ï¼‰
- å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
  - PyTorch
  - Transformers
  - PEFT (Parameter-Efficient Fine-Tuning)
  - TRL (Transformer Reinforcement Learning)
  - XCodec2
  - Gradio
  - OmegaConf
  - soundfile
  - datasets

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/laksjdjf/llasa-trainer.git
cd llasa-trainer

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆä¾‹ï¼‰
pip install torch transformers peft trl xcodec2 gradio omegaconf soundfile datasets
```

### ä½¿ã„æ–¹

#### 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™

JSONLå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã—ã¾ã™ï¼š

```jsonl
{"text": "ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚", "code": [1234, 5678, ...]}
{"text": "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼", "code": [9012, 3456, ...]}
```

- `text`: éŸ³å£°ã«å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
- `code`: å¯¾å¿œã™ã‚‹éŸ³å£°ã‚³ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

#### 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ

`config/example.yaml`ã‚’å‚è€ƒã«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼š

```yaml
# ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
data_dir: dataset/data.jsonl
output_dir: ./trained/MyModel
model_name: NandemoGHS/Anime-Llasa-3B

# CUDAè¨­å®š
cuda_visible_devices: "0"

# LoRAè¨­å®š
lora:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  bias: none
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj

# å­¦ç¿’è¨­å®š
training:
  num_train_epochs: 20
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 1e-4
  save_steps: 100
  fp16: true

# ãƒ†ã‚¹ãƒˆè¨­å®š
test:
  text: å¤©ä½¿ã¡ã‚ƒã‚“ãƒã‚¸å¤©ä½¿ã€‚
  interval: 50
```

#### 3. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ

```bash
python main.py --config config/your_config.yaml
```

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã€æŒ‡å®šã•ã‚ŒãŸé–“éš”ã§ãƒ†ã‚¹ãƒˆéŸ³å£°ãŒç”Ÿæˆã•ã‚Œã€é€²æ—ã‚’ç¢ºèªã§ãã¾ã™ã€‚

#### 4. æ¨è«–ï¼ˆéŸ³å£°ç”Ÿæˆï¼‰

å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦Gradio UIã§éŸ³å£°ã‚’ç”Ÿæˆï¼š

```bash
python gradio_tts_ui.py /path/to/trained/model
```

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯`./lora_checkpoints`ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒé–‹ãã€ä»¥ä¸‹ã®æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã™ï¼š
- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨æ­£è¦åŒ–ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
- ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ï¼ˆTemperatureã€Top-pã€Repeat Penaltyï¼‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç”Ÿæˆ
- ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ã‚¤ãƒƒã‚¯é¸æŠ

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
llasa-trainer/
â”œâ”€â”€ main.py                 # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ gradio_tts_ui.py       # Gradio Web UIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”œâ”€â”€ config/
â”‚   â””â”€â”€ example.yaml       # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹
â””â”€â”€ modules/
    â”œâ”€â”€ llasa.py           # LLASAãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹
    â”œâ”€â”€ llasa_utils.py     # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
    â”œâ”€â”€ train.py           # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
    â””â”€â”€ train_utils.py     # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼
```

### ãƒ¢ãƒ‡ãƒ«è©³ç´°

#### LLASAã‚¯ãƒ©ã‚¹

`modules.llasa.LLASA`ã‚¯ãƒ©ã‚¹ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ç”Ÿæˆã¾ã§ã®å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã¾ã™ï¼š

```python
from modules.llasa import LLASA

# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
llasa = LLASA.from_pretrained("./lora_checkpoints")

# éŸ³å£°ç”Ÿæˆ
audio_path, status, tokens = llasa.generate(
    text="ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚",
    temperature=0.7,
    top_p=0.9,
    repeat_penalty=1.1,
    max_tokens=300
)
```

### ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯[LICENSE](LICENSE)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### è¬è¾

- ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: [NandemoGHS/Anime-Llasa-3B](https://huggingface.co/NandemoGHS/Anime-Llasa-3B)
- ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ¼ãƒ‡ãƒƒã‚¯: [NandemoGHS/Anime-XCodec2](https://huggingface.co/NandemoGHS/Anime-XCodec2)

---

## English

### Overview

LLASA-Trainer is a training framework for fine-tuning the LLASA-3B (Large Language Audio Speech Architecture) model using LoRA. This project helps build high-quality Japanese TTS systems that generate speech from text.

### Features

- ğŸ¯ **LoRA-based Fine-tuning**: Efficient memory usage for model customization
- ğŸµ **XCodec2 Integration**: Neural codec for high-quality speech generation
- ğŸ¤ **Gradio Web UI**: Browser-based speech generation interface
- ğŸ“Š **Training Tests**: Automatic quality checks during training
- âš™ï¸ **Flexible Configuration**: YAML-based configuration management
- ğŸš€ **Easy Deployment**: Simple command-line interface

### Requirements

- Python 3.8+
- CUDA-capable GPU (recommended)
- Required Python packages:
  - PyTorch
  - Transformers
  - PEFT (Parameter-Efficient Fine-Tuning)
  - TRL (Transformer Reinforcement Learning)
  - XCodec2
  - Gradio
  - OmegaConf
  - soundfile
  - datasets

### Installation

```bash
# Clone the repository
git clone https://github.com/laksjdjf/llasa-trainer.git
cd llasa-trainer

# Install required packages (example)
pip install torch transformers peft trl xcodec2 gradio omegaconf soundfile datasets
```

### Usage

#### 1. Prepare Dataset

Prepare your dataset in JSONL format:

```jsonl
{"text": "Hello, it's nice weather today.", "code": [1234, 5678, ...]}
{"text": "Thank you very much!", "code": [9012, 3456, ...]}
```

- `text`: Text to convert to speech
- `code`: Corresponding speech codes (optional)

#### 2. Create Configuration File

Create a configuration file based on `config/example.yaml`:

```yaml
# Data and model paths
data_dir: dataset/data.jsonl
output_dir: ./trained/MyModel
model_name: NandemoGHS/Anime-Llasa-3B

# CUDA settings
cuda_visible_devices: "0"

# LoRA configuration
lora:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  bias: none
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj

# Training settings
training:
  num_train_epochs: 20
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 1e-4
  save_steps: 100
  fp16: true

# Test settings
test:
  text: Sample test text.
  interval: 50
```

#### 3. Run Training

```bash
python main.py --config config/your_config.yaml
```

During training, test audio will be generated at specified intervals to monitor progress.

#### 4. Inference (Speech Generation)

Use the trained model with Gradio UI for speech generation:

```bash
python gradio_tts_ui.py /path/to/trained/model
```

By default, it loads the model from `./lora_checkpoints`.

The browser interface opens with the following features:
- Text input with normalization preview
- Generation parameter adjustment (Temperature, Top-p, Repeat Penalty)
- Real-time speech generation
- Quick sample text selection

### Project Structure

```
llasa-trainer/
â”œâ”€â”€ main.py                 # Training entry point
â”œâ”€â”€ gradio_tts_ui.py       # Gradio Web UI interface
â”œâ”€â”€ config/
â”‚   â””â”€â”€ example.yaml       # Example configuration file
â””â”€â”€ modules/
    â”œâ”€â”€ llasa.py           # LLASA model class
    â”œâ”€â”€ llasa_utils.py     # Utility functions
    â”œâ”€â”€ train.py           # Training logic
    â””â”€â”€ train_utils.py     # Training helpers
```

### Model Details

#### LLASA Class

The `modules.llasa.LLASA` class provides a complete pipeline from text to speech generation:

```python
from modules.llasa import LLASA

# Load model
llasa = LLASA.from_pretrained("./lora_checkpoints")

# Generate speech
audio_path, status, tokens = llasa.generate(
    text="Hello, it's nice weather today.",
    temperature=0.7,
    top_p=0.9,
    repeat_penalty=1.1,
    max_tokens=300
)
```

### License

This project is released under the MIT License. See the [LICENSE](LICENSE) file for details.

### Acknowledgments

- Base model: [NandemoGHS/Anime-Llasa-3B](https://huggingface.co/NandemoGHS/Anime-Llasa-3B)
- Audio codec: [NandemoGHS/Anime-XCodec2](https://huggingface.co/NandemoGHS/Anime-XCodec2)
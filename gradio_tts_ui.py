"""
ã‚·ãƒ³ãƒ—ãƒ«ãªGradio TTS UI - LLASAã‚¯ãƒ©ã‚¹ä½¿ç”¨ç‰ˆ
"""

import gradio as gr
import os
import time
import argparse
from modules.llasa import LLASA
from modules.llasa_utils import normalize_text

# CUDAè¨­å®š
os.environ["CUDA_VISIBLE_DEVICES"] = "0"


def generate_speech(text: str, temperature: float = 0.7, top_p: float = 0.9, repeat_penalty: float = 1.0, max_tokens: int = 300):
    """æ™‚é–“è¨ˆæ¸¬ä»˜ãéŸ³å£°ç”Ÿæˆ"""
    start_time = time.time()
    
    audio_path, status, tokens = llasa.generate(text, temperature, top_p, repeat_penalty, max_tokens)
    
    elapsed_time = time.time() - start_time
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«æ™‚é–“æƒ…å ±ã‚’è¿½åŠ 
    if audio_path:
        status_with_time = f"âœ… ç”Ÿæˆå®Œäº†ï¼ â±ï¸ {elapsed_time:.2f}ç§’"
    else:
        status_with_time = f"âŒ {status} â±ï¸ {elapsed_time:.2f}ç§’"
    
    return audio_path, status_with_time, tokens

# Gradio UI
with gr.Blocks(title="LLASA TTS", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤ LLASA-3B TTS")
    
    with gr.Row():
        with gr.Column(scale=2):
            text_input = gr.Textbox(
                label="ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›",
                value="",
                lines=3
            )

            normalized_text = gr.Textbox(
                label="æ­£è¦åŒ–ãƒ†ã‚­ã‚¹ãƒˆ",
                interactive=False
            )
            
            with gr.Row():
                temperature = gr.Slider(0.1, 2.0, 0.7, step=0.01, label="Temperature")
                top_p = gr.Slider(0.1, 1.0, 0.9, step=0.01, label="Top-p")
                repeat_penalty = gr.Slider(0.1, 2.0, 1.1, step=0.01, label="Repeat Penalty")
            
            max_tokens = gr.Slider(50, 2000, 500, step=25, label="æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°")
            generate_btn = gr.Button("ğŸµ éŸ³å£°ç”Ÿæˆ", variant="primary", size="lg")
        
        with gr.Column(scale=1):
            audio_output = gr.Audio(label="ç”ŸæˆéŸ³å£°", type="filepath")
            status_output = gr.Textbox(label="çŠ¶æ…‹", interactive=False)
            token_output = gr.Textbox(label="ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±", interactive=False)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
    samples = [
        "ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚",
        "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼",
        "é ‘å¼µã£ã¦ï¼å¿œæ´ã—ã¦ã‚‹ã‚ˆï¼",
        "ãŠã¤ã‹ã‚Œã•ã¾ã§ã—ãŸã€‚"
    ]
    
    with gr.Row():
        for sample in samples:
            btn = gr.Button(f"ã€Œ{sample}...ã€", size="sm")
            btn.click(lambda s=sample: s, outputs=text_input)
    
    # ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š
    generate_btn.click(
        generate_speech,
        inputs=[text_input, temperature, top_p, repeat_penalty, max_tokens],
        outputs=[audio_output, status_output, token_output]
    )

    text_input.change(
        normalize_text,
        inputs=text_input,
        outputs=normalized_text
    )
    
    text_input.submit(
        generate_speech,
        inputs=[text_input, temperature, top_p, repeat_penalty, max_tokens],
        outputs=[audio_output, status_output, token_output]
    )

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LLASA TTS Gradio UI")
    parser.add_argument("model_path", nargs="?", default="./lora_checkpoints", help="Path to the LLASA model")
    parser.add_argument("--compile", action="store_true", help="Use torch.compile() for optimization (PyTorch 2.0+)")
    parser.add_argument("--bf16", action="store_true", help="Use bfloat16 precision (recommended for A100)")
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸš€ æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
    print(f"  - torch.compile(): {'æœ‰åŠ¹' if args.compile else 'ç„¡åŠ¹'}")
    print(f"  - bfloat16: {'æœ‰åŠ¹' if args.bf16 else 'ç„¡åŠ¹ (float16)'}")
    print("=" * 50)
    
    # LLASAãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆæœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
    llasa = LLASA.from_pretrained(args.model_path, compile_model=args.compile, use_bf16=args.bf16)
    llasa.model.merge_and_unload()
    demo.launch()
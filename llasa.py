"""
LLASA-3B TTS ç”Ÿæˆã‚¯ãƒ©ã‚¹
"""

import torch
import numpy as np
import tempfile
import soundfile as sf
import re
from transformers import AutoTokenizer, LogitsProcessor
from peft import AutoPeftModelForCausalLM
from xcodec2.modeling_xcodec2 import XCodec2Model


class LLASA:
    def __init__(self, model=None, tokenizer=None, codec_model=None):
        """LLASA-3B TTS ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        
        Args:
            model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆæ—¢ã«èª­ã¿è¾¼ã¿æ¸ˆã¿ã®å ´åˆï¼‰
            tokenizer: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ï¼ˆæ—¢ã«èª­ã¿è¾¼ã¿æ¸ˆã¿ã®å ´åˆï¼‰
            codec_model: XCodec2ãƒ¢ãƒ‡ãƒ«ï¼ˆæ—¢ã«èª­ã¿è¾¼ã¿æ¸ˆã¿ã®å ´åˆï¼‰
        """
        
        # ç›´æ¥æŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        if model is not None and tokenizer is not None and codec_model is not None:
            print("ğŸ¯ æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨...")
            self.model = model
            self.tokenizer = tokenizer
            self.codec_model = codec_model
        else:
            # æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã€ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã‚’ã™ã¹ã¦æŒ‡å®šã—ã¦ãã ã•ã„")
        
        # éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³è¨­å®š
        self._setup_speech_tokens()
        
        # ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–è¨­å®š
        self._setup_normalizer()
        
        print("âœ… LLASA åˆæœŸåŒ–å®Œäº†ï¼")
    
    @classmethod
    def from_pretrained(cls, lora_path: str = "./lora_checkpoints"):
        """ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‹ã‚‰ LLASA ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        
        print("ğŸš€ LLASA ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        # CUDAè¨­å®š
        torch.cuda.empty_cache()
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print("ğŸ“¦ LoRAãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        model = AutoPeftModelForCausalLM.from_pretrained(
            lora_path,
            torch_dtype=torch.float16,
        ).eval().to('cuda:0')
        model.merge_and_unload()
        
        print("ğŸ“ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼èª­ã¿è¾¼ã¿ä¸­...")
        tokenizer = AutoTokenizer.from_pretrained(lora_path)
        
        print("ğŸµ XCodec2ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        codec_model = XCodec2Model.from_pretrained(
            "NandemoGHS/Anime-XCodec2",
        ).eval().to('cuda:0')
        
        return cls(model=model, tokenizer=tokenizer, codec_model=codec_model)
    
    def _setup_speech_tokens(self):
        """éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³è¨­å®šã‚’åˆæœŸåŒ–"""
        self.speech_start_id = self.tokenizer.convert_tokens_to_ids('<|s_0|>')
        self.speech_end_id = self.tokenizer.convert_tokens_to_ids('<|SPEECH_GENERATION_END|>')
        
        # LogitsProcessorè¨­å®š
        speech_token_ids = list(range(self.speech_start_id, self.speech_start_id + 65536))
        allowed_tokens = torch.tensor(speech_token_ids + [self.speech_end_id], dtype=torch.long)
        mask = torch.full((193800,), float('-inf'))
        mask[allowed_tokens] = 0.0
        mask = mask.unsqueeze(0).to("cuda:0", dtype=torch.float16)
        self.speech_processor = SpeechOnlyProcessor(mask)
        
        # ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–è¨­å®š
        self._setup_normalizer()
        
        print("âœ… LLASA åˆæœŸåŒ–å®Œäº†ï¼")
    
    def _setup_normalizer(self):
        """ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ã®è¨­å®š"""
        self.replace_map = {
            r"\t": "",
            r"\[n\]": "",
            r" ": "",
            r"ã€€": "",
            r"[;â–¼â™€â™‚ã€Šã€‹â‰ªâ‰«â‘ â‘¡â‘¢â‘£â‘¤â‘¥]": "",
            r"[\u02d7\u2010-\u2015\u2043\u2212\u23af\u23e4\u2500\u2501\u2e3a\u2e3b]": "",
            r"[\uff5e\u301C]": "ãƒ¼",
            r"ï¼Ÿ": "?",
            r"ï¼": "!",
            r"[â—â—¯ã€‡]": "â—‹",
            r"â™¥": "â™¡",
        }
        
        self.fullwidth_alpha_to_halfwidth = str.maketrans({
            chr(full): chr(half)
            for full, half in zip(
                list(range(0xFF21, 0xFF3B)) + list(range(0xFF41, 0xFF5B)),
                list(range(0x41, 0x5B)) + list(range(0x61, 0x7B)),
            )
        })
        
        self.halfwidth_katakana_to_fullwidth = str.maketrans({
            chr(half): chr(full)
            for half, full in zip(range(0xFF61, 0xFF9F), range(0x30A1, 0x30FB))
        })
        
        self.fullwidth_digits_to_halfwidth = str.maketrans({
            chr(full): chr(half)
            for full, half in zip(range(0xFF10, 0xFF1A), range(0x30, 0x3A))
        })
        
        self.invalid_pattern = re.compile(
            r"[^\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\u3400-\u4DBF\u3005"
            r"\u0041-\u005A\u0061-\u007A"
            r"\u0030-\u0039"
            r"ã€‚ã€!?â€¦â™ªâ™¡â—‹]"
        )
    
    def normalize_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–"""
        for pattern, replacement in self.replace_map.items():
            text = re.sub(pattern, replacement, text)
        
        text = text.translate(self.fullwidth_alpha_to_halfwidth)
        text = text.translate(self.fullwidth_digits_to_halfwidth)
        text = text.translate(self.halfwidth_katakana_to_fullwidth)
        text = self.invalid_pattern.sub("", text)
        text = re.sub(r"â€¦{3,}", "â€¦â€¦", text)
        
        return text
    
    @torch.no_grad()
    def generate(
        self,
        text: str,
        temperature: float = 0.7,
        top_p: float = 0.9,
        repeat_penalty: float = 1.0,
        max_tokens: int = 300,
    ) -> tuple[str, str, str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆ
        
        Returns:
            tuple[audio_path, status_msg, token_info]
        """
        
        # ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
        text = self.normalize_text(text)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        formatted_text = f"<|TEXT_UNDERSTANDING_START|>{text}<|TEXT_UNDERSTANDING_END|>"
        chat = [
            {"role": "user", "content": "Convert the text to speech:" + formatted_text},
            {"role": "assistant", "content": "<|SPEECH_GENERATION_START|>"}
        ]
        
        # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        input_ids = self.tokenizer.apply_chat_template(
            chat, tokenize=True, return_tensors='pt', continue_final_message=True
        ).to('cuda:0')
        
        # éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ
        outputs = self.model.generate(
            input_ids,
            max_new_tokens=max_tokens,
            eos_token_id=self.speech_end_id,
            do_sample=True,
            top_p=top_p,
            temperature=temperature,
            repetition_penalty=repeat_penalty,
            use_cache=True,
            pad_token_id=self.tokenizer.pad_token_id,
            logits_processor=[self.speech_processor],
        )
        
        # éŸ³å£°IDã‚’æŠ½å‡º
        generated_ids = outputs[0][input_ids.shape[1]:]
        speech_ids = []
        
        for token_id in generated_ids:
            token_id_val = token_id.item()
            
            # çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ã§åœæ­¢
            if token_id_val == self.speech_end_id:
                break
                
            # éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
            if self.speech_start_id <= token_id_val < self.speech_start_id + 65536:
                speech_id = token_id_val - self.speech_start_id
                speech_ids.append(speech_id)
        
        if not speech_ids:
            return None, "âŒ æœ‰åŠ¹ãªéŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ", ""
        
        # éŸ³å£°æ³¢å½¢ç”Ÿæˆ
        speech_codes = torch.tensor(speech_ids, dtype=torch.long).to('cuda:0').unsqueeze(0).unsqueeze(0)
        gen_wav = self.codec_model.decode_code(speech_codes)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            sf.write(tmp_file.name, gen_wav[0, 0, :].cpu().numpy(), 16000)
            audio_path = tmp_file.name
        
        status_msg = f"âœ… ç”Ÿæˆå®Œäº† ({len(speech_ids)} tokens)"
        token_info = str(speech_ids[:10]) + ("..." if len(speech_ids) > 10 else "")
        
        return audio_path, status_msg, token_info


class SpeechOnlyProcessor(LogitsProcessor):
    """éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’è¨±å¯ã™ã‚‹LogitsProcessor"""
    
    def __init__(self, mask):
        self.mask = mask
    
    def __call__(self, input_ids, scores):
        return scores + self.mask

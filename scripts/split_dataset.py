#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã«åˆ†å‰²ã—ã¾ã™ã€‚
éå­¦ç¿’ã‚’é˜²ãã€ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«å¿…è¦ã§ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/split_dataset.py input.jsonl --train-ratio 0.9

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    --train-ratio: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.9ï¼‰
    --output-dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: datasetï¼‰
    --shuffle: ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
    --seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 42ï¼‰
"""

import argparse
import json
import random
from pathlib import Path


def split_dataset(
    input_file: str,
    train_ratio: float = 0.9,
    output_dir: str = "dataset",
    shuffle: bool = True,
    seed: int = 42
):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å­¦ç¿’ç”¨ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã«åˆ†å‰²"""
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    input_path = Path(input_file)
    if not input_path.exists():
        raise FileNotFoundError(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­: {input_file}")
    with open(input_path, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f if line.strip()]
    
    total_count = len(data)
    print(f"ğŸ“Š ç·ãƒ‡ãƒ¼ã‚¿æ•°: {total_count}ä»¶")
    
    if total_count == 0:
        raise ValueError("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
    
    # ã‚·ãƒ£ãƒƒãƒ•ãƒ«
    if shuffle:
        random.seed(seed)
        random.shuffle(data)
        print(f"ğŸ”€ ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ï¼ˆseed={seed}ï¼‰")
    
    # åˆ†å‰²
    split_idx = int(total_count * train_ratio)
    train_data = data[:split_idx]
    val_data = data[split_idx:]
    
    train_count = len(train_data)
    val_count = len(val_data)
    
    print(f"âœ‚ï¸ ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²:")
    print(f"   å­¦ç¿’: {train_count}ä»¶ ({train_count/total_count*100:.1f}%)")
    print(f"   ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: {val_count}ä»¶ ({val_count/total_count*100:.1f}%)")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜
    train_file = output_path / "train.jsonl"
    val_file = output_path / "val.jsonl"
    
    print(f"ğŸ’¾ ä¿å­˜ä¸­...")
    with open(train_file, 'w', encoding='utf-8') as f:
        for item in train_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    print(f"   å­¦ç¿’: {train_file}")
    
    with open(val_file, 'w', encoding='utf-8') as f:
        for item in val_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    print(f"   ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: {val_file}")
    
    print("âœ… å®Œäº†ï¼")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. config/example.yaml ã‚’ç·¨é›†")
    print(f"   data_dir: {train_file}")
    print(f"   eval_data_dir: {val_file}")
    print("2. å­¦ç¿’ã‚’å®Ÿè¡Œ")
    print("   python main.py --config config/example.yaml")


def main():
    parser = argparse.ArgumentParser(
        description="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å­¦ç¿’ç”¨ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã«åˆ†å‰²",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    # åŸºæœ¬çš„ãªä½¿ã„æ–¹ï¼ˆ90%å­¦ç¿’ã€10%ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    python scripts/split_dataset.py dataset/all_data.jsonl
    
    # æ¯”ç‡ã‚’å¤‰æ›´ï¼ˆ80%å­¦ç¿’ã€20%ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    python scripts/split_dataset.py dataset/all_data.jsonl --train-ratio 0.8
    
    # å‡ºåŠ›å…ˆã‚’å¤‰æ›´
    python scripts/split_dataset.py dataset/all_data.jsonl --output-dir my_dataset
    
    # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ãªã—
    python scripts/split_dataset.py dataset/all_data.jsonl --no-shuffle
        """
    )
    
    parser.add_argument(
        "input_file",
        type=str,
        help="å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJSONLå½¢å¼ï¼‰"
    )
    
    parser.add_argument(
        "--train-ratio",
        type=float,
        default=0.9,
        help="å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.9ï¼‰"
    )
    
    parser.add_argument(
        "--output-dir",
        type=str,
        default="dataset",
        help="å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: datasetï¼‰"
    )
    
    parser.add_argument(
        "--no-shuffle",
        action="store_true",
        help="ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ãªã„"
    )
    
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 42ï¼‰"
    )
    
    args = parser.parse_args()
    
    try:
        split_dataset(
            input_file=args.input_file,
            train_ratio=args.train_ratio,
            output_dir=args.output_dir,
            shuffle=not args.no_shuffle,
            seed=args.seed
        )
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
